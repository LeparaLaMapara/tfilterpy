{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tfilterpy.module_functions import KalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1, 1, 1],\n",
    "                [2, 2, 2],\n",
    "                [3, 3, 3],\n",
    "                [4, 4, 4],\n",
    "                [5, 5, 5],\n",
    "                [6, 6, 6],\n",
    "                [7, 7, 7],\n",
    "                [8, 8, 8],\n",
    "                [9, 9, 9],\n",
    "                [10, 10, 10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "F  = np.array([[1, 0.1, 0.01],\n",
    "            [0, 1, 0.1],\n",
    "            [0, 0, 1]])\n",
    "H  = np.array([[1, 0, 0],\n",
    "            [0, 1, 0],\n",
    "            [0, 0, 1]])\n",
    "Q  = np.eye(3) * 0.01\n",
    "R  = np.eye(3) * 0.1\n",
    "x0 = np.array([0, 0, 0])\n",
    "P0 = np.eye(3) *0.1165161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Kalman filter\n",
    "kf = KalmanFilter(F, H, Q, R, x0, P0)\n",
    "\n",
    "# Run the Kalman filter on the data\n",
    "state_estimates = kf.run(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58343517, 0.60375998, 0.58105494],\n",
       "       [1.23038307, 1.27315939, 1.18235292],\n",
       "       [1.97116322, 2.03289095, 1.83424543],\n",
       "       [2.8091638 , 2.88147217, 2.54193243],\n",
       "       [3.73797143, 3.80957745, 3.30274215],\n",
       "       [4.74630461, 4.80475675, 4.11014155],\n",
       "       [5.82117601, 5.85409372, 4.95609638],\n",
       "       [6.94990705, 6.94573035, 5.83259004],\n",
       "       [8.12120247, 8.06957069, 6.7324676 ],\n",
       "       [9.3255598 , 9.21744614, 7.64978288]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New particle state: [-8.78541111 29.83876633  3.00037625  4.00037625]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MotionModel:\n",
    "    def __init__(self, alpha, delta_t):\n",
    "        self.alpha = alpha\n",
    "        self.delta_t = delta_t\n",
    "\n",
    "    def sample(self, particle):\n",
    "        noise = np.random.normal(0, np.sqrt(self.alpha[0]*particle[0]**2 +\n",
    "                                            self.alpha[1]*particle[1]**2 +\n",
    "                                            self.alpha[2]*particle[2]**2 +\n",
    "                                            self.alpha[3]*particle[3]**2))\n",
    "        x = particle[0] + (particle[2]/particle[3])*(np.sin(particle[3]*(self.delta_t + particle[3]/2)) - np.sin(particle[3]*particle[3]/2))/self.alpha[3] + noise*np.sin(particle[3]*(self.delta_t + particle[3]/2))\n",
    "        y = particle[1] + (particle[2]/particle[3])*(-np.cos(particle[3]*(self.delta_t + particle[3]/2)) + np.cos(particle[3]*particle[3]/2))/self.alpha[3] + noise*np.cos(particle[3]*(self.delta_t + particle[3]/2))\n",
    "        velocity = particle[2] + noise*self.alpha[4]*self.delta_t\n",
    "        yaw_rate = particle[3] + noise*self.alpha[5]*self.delta_t\n",
    "\n",
    "        return np.array([x, y, velocity, yaw_rate])\n",
    "\n",
    "# Create an instance of MotionModel\n",
    "alpha = [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
    "delta_t = 0.1\n",
    "motion_model = MotionModel(alpha, delta_t)\n",
    "\n",
    "# Sample a new particle state from the motion model\n",
    "particle = np.array([1, 2, 3, 4])\n",
    "new_particle = motion_model.sample(particle)\n",
    "print(\"New particle state:\", new_particle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood of observation given state: 0.44153214202960805\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define state and observation dimensions\n",
    "state_dim = 2\n",
    "obs_dim = 1\n",
    "\n",
    "# Generate random observation matrix and covariance matrix\n",
    "H = np.random.rand(obs_dim, state_dim)\n",
    "R = np.random.rand(obs_dim, obs_dim)\n",
    "\n",
    "# Define an observation model\n",
    "observation_model = ObservationModel(state_dim, obs_dim, H, R)\n",
    "\n",
    "# Generate some random data\n",
    "state = np.random.rand(state_dim)\n",
    "observation = np.random.rand(obs_dim)\n",
    "\n",
    "# Compute the likelihood of the observation given the state\n",
    "likelihood = observation_model.likelihood(state, observation)\n",
    "\n",
    "print(f\"Likelihood of observation given state: {likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SystematicResampling:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def resample(particles, weights):\n",
    "        M = len(particles)\n",
    "        cum_weights = np.cumsum(weights)\n",
    "        cum_weights[-1] = 1.0  # make sure weights sum to 1\n",
    "\n",
    "        # draw random numbers and add equally spaced offsets\n",
    "        # to obtain resampled indices\n",
    "        r = np.random.uniform(0, 1/M)\n",
    "        resampled_indices = np.zeros(M, dtype=int)\n",
    "        for i in range(M):\n",
    "            u = r + i/M\n",
    "            j = np.searchsorted(cum_weights, u)\n",
    "            resampled_indices[i] = j\n",
    "\n",
    "        # resample particles and weights\n",
    "        new_particles = particles[resampled_indices]\n",
    "        new_weights = np.ones(M) / M\n",
    "\n",
    "        return new_particles, new_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ParticleFilter:\n",
    "    \n",
    "    def __init__(self, num_particles, state_dim, motion_model, observation_model, resampling_method):\n",
    "        self.num_particles = num_particles\n",
    "        self.state_dim = state_dim\n",
    "        self.motion_model = motion_model\n",
    "        self.observation_model = observation_model\n",
    "        self.resampling_method = resampling_method\n",
    "        \n",
    "        self.particles = np.zeros((self.num_particles, self.state_dim))\n",
    "        self.weights = np.ones(self.num_particles) / self.num_particles\n",
    "    \n",
    "    def predict(self):\n",
    "        new_particles = []\n",
    "        for particle in self.particles:\n",
    "            new_particles.append(self.motion_model.sample(particle))\n",
    "        self.particles = np.array(new_particles)\n",
    "    \n",
    "    def update(self, observation):\n",
    "        weights = []\n",
    "        for particle in self.particles:\n",
    "            weights.append(self.observation_model.likelihood(observation, particle))\n",
    "        weights = np.array(weights)\n",
    "        self.weights = weights / np.sum(weights)\n",
    "    \n",
    "    def resample(self):\n",
    "        indices = self.resampling_method.resample(self.weights)\n",
    "        self.particles = self.particles[indices]\n",
    "        self.weights = np.ones(self.num_particles) / self.num_particles\n",
    "    \n",
    "    def run(self, observations):\n",
    "        state_estimates = []\n",
    "        for observation in observations:\n",
    "            self.predict()\n",
    "            self.update(observation)\n",
    "            state_estimate = self.compute_state_estimate()\n",
    "            state_estimates.append(state_estimate)\n",
    "            self.resample()\n",
    "        return np.array(state_estimates)\n",
    "    \n",
    "    def compute_state_estimate(self):\n",
    "        return np.average(self.particles, weights=self.weights, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1348\\4024268082.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mestimated_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeasurements\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mpf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mpf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeasurements\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mestimated_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state_estimate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1348\\1159585370.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mnew_particles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mparticle\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mnew_particles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmotion_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparticle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparticles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_particles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1348\\3560439469.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, particle)\u001b[0m\n\u001b[0;32m      9\u001b[0m         noise = np.random.normal(0, np.sqrt(self.alpha[0]*particle[0]**2 +\n\u001b[0;32m     10\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mparticle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mparticle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                                             self.alpha[3]*particle[3]**2))\n\u001b[0;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparticle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mparticle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mparticle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparticle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta_t\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mparticle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparticle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mparticle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparticle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta_t\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mparticle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Define resampling method\n",
    "resampling_method = SystematicResampling\n",
    "\n",
    "# Define initial particles and weights\n",
    "num_particles = 100\n",
    "state_dim=2\n",
    "initial_particles = np.random.normal(size=(num_particles, 3))\n",
    "initial_weights = np.ones(num_particles) / num_particles\n",
    "\n",
    "# Create particle filter object\n",
    "pf = ParticleFilter(num_particles, state_dim, motion_model, observation_model, resampling_method)\n",
    "\n",
    "# Generate measurements\n",
    "true_state = np.array([0.0, 0.0, 0.0])\n",
    "measurements = []\n",
    "for t in range(50):\n",
    "    true_state = motion_model_fn(true_state, np.array([0.5, 0.1]))\n",
    "    obs = np.random.normal(loc=true_state[:2], scale=0.5)\n",
    "    measurements.append(obs)\n",
    "\n",
    "# Run particle filter\n",
    "estimated_states = []\n",
    "for t in range(len(measurements)):\n",
    "    pf.predict()\n",
    "    pf.update(measurements[t])\n",
    "    estimated_state = pf.get_state_estimate()\n",
    "    estimated_states.append(estimated_state)\n",
    "    \n",
    "# Plot estimated trajectory and measurements\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "true_trajectory = [motion_model_fn(true_state, np.array([0.5, 0.1])) for t in range(len(measurements))]\n",
    "true_trajectory = np.array(true_trajectory)\n",
    "\n",
    "estimated_states = np.array(estimated_states)\n",
    "measurements = np.array(measurements)\n",
    "\n",
    "plt.plot(true_trajectory[:,0], true_trajectory[:,1], label='True Trajectory')\n",
    "plt.plot(estimated_states[:,0], estimated_states[:,1], label='Estimated Trajectory')\n",
    "plt.scatter(measurements[:,0], measurements[:,1], label='Measurements')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((num_particles, state_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'initial_covariance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m R_dask \u001b[38;5;241m=\u001b[39m da\u001b[38;5;241m.\u001b[39mfrom_array(R, chunks\u001b[38;5;241m=\u001b[39mR\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Instantiate the Kalman Filter\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Using NumPy arrays:\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m kf_numpy \u001b[38;5;241m=\u001b[39m \u001b[43mDaskKalmanFilter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_transition_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mF\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservation_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocess_noise_cov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservation_noise_cov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_state\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Alternatively, instantiate using Dask arrays:\u001b[39;00m\n\u001b[0;32m     42\u001b[0m kf_dask \u001b[38;5;241m=\u001b[39m DaskKalmanFilter(\n\u001b[0;32m     43\u001b[0m     state_transition_matrix\u001b[38;5;241m=\u001b[39mF_dask,\n\u001b[0;32m     44\u001b[0m     observation_matrix\u001b[38;5;241m=\u001b[39mH_dask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     initial_state\u001b[38;5;241m=\u001b[39mda\u001b[38;5;241m.\u001b[39mfrom_array(initial_state, chunks\u001b[38;5;241m=\u001b[39minitial_state\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     48\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'initial_covariance'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the DaskKalmanFilter from TFilterPy\n",
    "from TFilterPy.state_estimation.linear_filters import DaskKalmanFilter\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Define the system model parameters for a simple constant velocity model\n",
    "# ------------------------------------------------------------------\n",
    "F = np.array([[1, 1],\n",
    "              [0, 1]])  # State transition matrix\n",
    "\n",
    "H = np.array([[1, 0]])  # Observation matrix\n",
    "\n",
    "# Noise covariances\n",
    "Q = np.eye(2) * 0.01  # Process noise covariance\n",
    "R = np.eye(1) * 0.1   # Observation noise covariance\n",
    "\n",
    "# Initial state vector\n",
    "initial_state = np.array([0, 1])\n",
    "\n",
    "# Optionally convert some arrays to Dask arrays for distributed computation\n",
    "F_dask = da.from_array(F, chunks=F.shape)\n",
    "H_dask = da.from_array(H, chunks=H.shape)\n",
    "Q_dask = da.from_array(Q, chunks=Q.shape)\n",
    "R_dask = da.from_array(R, chunks=R.shape)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Instantiate the Kalman Filter\n",
    "# ------------------------------------------------------------------\n",
    "# Using NumPy arrays:\n",
    "kf_numpy = DaskKalmanFilter(\n",
    "    state_transition_matrix=F,\n",
    "    observation_matrix=H,\n",
    "    process_noise_cov=Q,\n",
    "    observation_noise_cov=R,\n",
    "    initial_state=initial_state\n",
    ")\n",
    "\n",
    "# Alternatively, instantiate using Dask arrays:\n",
    "kf_dask = DaskKalmanFilter(\n",
    "    state_transition_matrix=F_dask,\n",
    "    observation_matrix=H_dask,\n",
    "    process_noise_cov=Q_dask,\n",
    "    observation_noise_cov=R_dask,\n",
    "    initial_state=da.from_array(initial_state, chunks=initial_state.shape)\n",
    ")\n",
    "\n",
    "print(\"Filter instances created.\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Simulate a series of measurements\n",
    "# ------------------------------------------------------------------\n",
    "num_steps = 50\n",
    "true_states = []\n",
    "measurements = []\n",
    "\n",
    "# Starting true state\n",
    "x = initial_state.copy()\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "for _ in range(num_steps):\n",
    "    # Evolve the true state using the state transition model\n",
    "    x = F @ x\n",
    "    true_states.append(x.copy())\n",
    "    \n",
    "    # Simulate a measurement of the position with added noise\n",
    "    measurement = H @ x + np.random.normal(0, np.sqrt(R[0, 0]))\n",
    "    measurements.append(measurement.item())\n",
    "\n",
    "print(\"Simulation complete.\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Run the filter over the simulated measurements\n",
    "# ------------------------------------------------------------------\n",
    "estimated_states = []\n",
    "\n",
    "# This loop assumes that your DaskKalmanFilter class implements the following methods:\n",
    "# - predict() : to perform the prediction step\n",
    "# - update(z) : to update the state with measurement z\n",
    "# - state     : to retrieve the current state estimate\n",
    "for z in measurements:\n",
    "    kf_numpy.predict()\n",
    "    kf_numpy.update(z)\n",
    "    estimated_states.append(kf_numpy.state.copy())\n",
    "\n",
    "print(\"Filtering complete.\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Visualize the results\n",
    "# ------------------------------------------------------------------\n",
    "# Extract the positions (assumed to be the first element in the state vector)\n",
    "true_positions = [s[0] for s in true_states]\n",
    "estimated_positions = [s[0] for s in estimated_states]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(true_positions, label='True Position', marker='o')\n",
    "plt.plot(estimated_positions, label='Estimated Position', marker='x')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Position')\n",
    "plt.title('True vs. Estimated Position')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff4b1fca65a764b45acb559e482afe389d289dd599b9f8c5fd12ff5c2ea46a65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
